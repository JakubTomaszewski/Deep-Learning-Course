{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wstęp do przetwarzania języka naturalnego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kuba/miniforge3/envs/SSNE/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x147aaab50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    \"\"\"Returns the available device for computation.\n",
    "    Returns:\n",
    "        torch.device: available device for computation\n",
    "    \"\"\"\n",
    "    compute_device = None\n",
    "    if torch.cuda.is_available():\n",
    "        compute_device = torch.device('cuda')\n",
    "    elif torch.backends.mps.is_available():\n",
    "        compute_device = torch.device('mps')\n",
    "    else:\n",
    "        compute_device = torch.device('cpu')\n",
    "    \n",
    "    print(f'device is {compute_device}')\n",
    "    return compute_device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = get_device()\n",
    "device = torch.device(\"cpu\") \n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Średniowieczne podejścia - bag of words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words - słownik z policzonymi wystąpieniami kazdego wyrazu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(\"data/sst2.tsv\", delimiter=\"\\t\", quoting=3).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hide new secretions from the parental units</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>contains no wit , only labored gags</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>that loves its characters and communicates som...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>remains utterly satisfied to remain the same t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>on the worst revenge-of-the-nerds clichés the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67344</th>\n",
       "      <td>a delightful comedy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67345</th>\n",
       "      <td>anguish , anger and frustration</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67346</th>\n",
       "      <td>at achieving the modest , crowd-pleasing goals...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67347</th>\n",
       "      <td>a patient viewer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67348</th>\n",
       "      <td>this new jangle of noise , mayhem and stupidit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67349 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  label\n",
       "0           hide new secretions from the parental units       0\n",
       "1                   contains no wit , only labored gags       0\n",
       "2      that loves its characters and communicates som...      1\n",
       "3      remains utterly satisfied to remain the same t...      0\n",
       "4      on the worst revenge-of-the-nerds clichés the ...      0\n",
       "...                                                  ...    ...\n",
       "67344                               a delightful comedy       1\n",
       "67345                   anguish , anger and frustration       0\n",
       "67346  at achieving the modest , crowd-pleasing goals...      1\n",
       "67347                                  a patient viewer       1\n",
       "67348  this new jangle of noise , mayhem and stupidit...      0\n",
       "\n",
       "[67349 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on the worst revenge-of-the-nerds clichés the filmmakers could dredge up \n"
     ]
    }
   ],
   "source": [
    "print(reviews[\"sentence\"][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "nltk.data.path.append('/Users/Kuba/Coding/nltk_data')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_words(raw_review):\n",
    "    \"\"\"Function to convert a review to a string of words.\n",
    "    The input is a single string (a raw moviw review), and the output is a single string (a preprocessed movie review)\"\"\"\n",
    "    review_text = BeautifulSoup(raw_review, 'lxml').get_text()\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "    words = letters_only.lower().split()\n",
    "    stops = set(stopwords.words('english'))\n",
    "    meaningful_words = [word for word in words if not word in stops]\n",
    "    return \" \".join(meaningful_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'on the worst revenge-of-the-nerds clichés the filmmakers could dredge up '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['sentence'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "worst revenge nerds clich filmmakers could dredge\n"
     ]
    }
   ],
   "source": [
    "clean_review = review_to_words(reviews['sentence'][4])\n",
    "print(clean_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kuba/miniforge3/envs/SSNE/lib/python3.8/site-packages/bs4/__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1000 of 67349\n",
      "Review 2000 of 67349\n",
      "Review 3000 of 67349\n",
      "Review 4000 of 67349\n",
      "Review 5000 of 67349\n",
      "Review 6000 of 67349\n",
      "Review 7000 of 67349\n",
      "Review 8000 of 67349\n",
      "Review 9000 of 67349\n",
      "Review 10000 of 67349\n",
      "Review 11000 of 67349\n",
      "Review 12000 of 67349\n",
      "Review 13000 of 67349\n",
      "Review 14000 of 67349\n",
      "Review 15000 of 67349\n",
      "Review 16000 of 67349\n",
      "Review 17000 of 67349\n",
      "Review 18000 of 67349\n",
      "Review 19000 of 67349\n",
      "Review 20000 of 67349\n",
      "Review 21000 of 67349\n",
      "Review 22000 of 67349\n",
      "Review 23000 of 67349\n",
      "Review 24000 of 67349\n",
      "Review 25000 of 67349\n",
      "Review 26000 of 67349\n",
      "Review 27000 of 67349\n",
      "Review 28000 of 67349\n",
      "Review 29000 of 67349\n",
      "Review 30000 of 67349\n",
      "Review 31000 of 67349\n",
      "Review 32000 of 67349\n",
      "Review 33000 of 67349\n",
      "Review 34000 of 67349\n",
      "Review 35000 of 67349\n",
      "Review 36000 of 67349\n",
      "Review 37000 of 67349\n",
      "Review 38000 of 67349\n",
      "Review 39000 of 67349\n",
      "Review 40000 of 67349\n",
      "Review 41000 of 67349\n",
      "Review 42000 of 67349\n",
      "Review 43000 of 67349\n",
      "Review 44000 of 67349\n",
      "Review 45000 of 67349\n",
      "Review 46000 of 67349\n",
      "Review 47000 of 67349\n",
      "Review 48000 of 67349\n",
      "Review 49000 of 67349\n",
      "Review 50000 of 67349\n",
      "Review 51000 of 67349\n",
      "Review 52000 of 67349\n",
      "Review 53000 of 67349\n",
      "Review 54000 of 67349\n",
      "Review 55000 of 67349\n",
      "Review 56000 of 67349\n",
      "Review 57000 of 67349\n",
      "Review 58000 of 67349\n",
      "Review 59000 of 67349\n",
      "Review 60000 of 67349\n",
      "Review 61000 of 67349\n",
      "Review 62000 of 67349\n",
      "Review 63000 of 67349\n",
      "Review 64000 of 67349\n",
      "Review 65000 of 67349\n",
      "Review 66000 of 67349\n",
      "Review 67000 of 67349\n"
     ]
    }
   ],
   "source": [
    "num_reviews = reviews['sentence'].size\n",
    "\n",
    "# Initialize an empty list to hold the clean reviews\n",
    "clean_train_reviews = []\n",
    "\n",
    "# Loop over each review; create an index i that goes from 0 to the length of the move review list\n",
    "for review in range(0, num_reviews):\n",
    "    # If the index is evenly divisible by 100, print a message\n",
    "    if (review+1) % 1000 == 0:\n",
    "        print('Review {} of {}'.format(review+1, num_reviews))\n",
    "    # Call our function for each one, and add the result to the list of clean reviews\n",
    "    clean_train_reviews.append(review_to_words(reviews['sentence'][review]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "Bag of words completed\n"
     ]
    }
   ],
   "source": [
    "print('Creating the bag of words...')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's bag of words tool.\n",
    "vectorizer = CountVectorizer(analyzer = 'word',\n",
    "                            tokenizer = None,\n",
    "                            preprocessor = None,\n",
    "                            stop_words = None,\n",
    "                            max_features = 1000)\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocaulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of strings.\n",
    "train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an array\n",
    "train_data_features = train_data_features.toarray()\n",
    "print('Bag of words completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Kuba/miniforge3/envs/SSNE/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = np.random.rand(len(reviews))>0.3\n",
    "train_data = torch.from_numpy(train_data_features).float()[train_indices]\n",
    "train_targets = torch.from_numpy(reviews[\"label\"].values[train_indices]).long()\n",
    "\n",
    "test_data = torch.from_numpy(train_data_features[~train_indices]).float()\n",
    "test_targets = torch.from_numpy(reviews[\"label\"].values[~train_indices]).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = data.TensorDataset(train_data,train_targets)\n",
    "test_dataset = data.TensorDataset(test_data,test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
    "test_loader = data.DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoWClassifier(\n",
       "  (lin1): Linear(in_features=1000, out_features=500, bias=True)\n",
       "  (act1): LeakyReLU(negative_slope=0.01)\n",
       "  (lin2): Linear(in_features=500, out_features=50, bias=True)\n",
       "  (act2): LeakyReLU(negative_slope=0.01)\n",
       "  (lin3): Linear(in_features=50, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BoWClassifier(nn.Module):\n",
    "    def __init__(self): \n",
    "        super(BoWClassifier, self).__init__()\n",
    "        self.lin1 =nn.Linear(1000, 500)  # na wejściu rozmiar słownika BoW\n",
    "        self.act1 =nn.LeakyReLU()\n",
    "        self.lin2 =nn.Linear(500, 50)\n",
    "        self.act2 =nn.LeakyReLU()\n",
    "        self.lin3 =nn.Linear(50, 5)\n",
    "        \n",
    "             \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.lin3(x)\n",
    "        return x\n",
    "bow_model = BoWClassifier().to(device)\n",
    "bow_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, data_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for imgs, labels in data_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        output = model(imgs)\n",
    "        pred = output.max(1, keepdim=True)[1] # get the index of the max logit\n",
    "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        total += imgs.shape[0]\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss 0.532 test_acc: 0.757\n",
      "Epoch 1 loss 0.432 test_acc: 0.78\n",
      "Epoch 2 loss 0.385 test_acc: 0.79\n",
      "Epoch 3 loss 0.344 test_acc: 0.801\n",
      "Epoch 4 loss 0.311 test_acc: 0.806\n",
      "Epoch 5 loss 0.291 test_acc: 0.811\n",
      "Epoch 6 loss 0.277 test_acc: 0.812\n",
      "Epoch 7 loss 0.266 test_acc: 0.811\n",
      "Epoch 8 loss 0.26 test_acc: 0.81\n",
      "Epoch 9 loss 0.255 test_acc: 0.816\n",
      "Final Training Accuracy: 0.8640030570652174\n",
      "Final Validation Accuracy: 0.8164738455453376\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(bow_model.parameters(), lr=0.001)\n",
    "\n",
    "iters = []\n",
    "losses = []\n",
    "train_acc = []\n",
    "val_acc = []\n",
    "for n in range(10):\n",
    "    epoch_losses = []\n",
    "    for x, labels in iter(train_loader):\n",
    "        x, labels = x.to(device), labels.to(device)\n",
    "        bow_model.train() \n",
    "        out = bow_model(x).squeeze()           \n",
    "\n",
    "        loss = criterion(out, labels)\n",
    "        loss.backward()  \n",
    "        epoch_losses.append(loss.item())\n",
    "        optimizer.step()              \n",
    "        optimizer.zero_grad()         \n",
    "\n",
    "    loss_mean = np.array(epoch_losses).mean()\n",
    "    iters.append(n)\n",
    "    losses.append(loss_mean)\n",
    "    test_acc = get_accuracy(bow_model, test_loader)\n",
    "    print(f\"Epoch {n} loss {loss_mean:.3} test_acc: {test_acc:.3}\")\n",
    "    train_acc.append(get_accuracy(bow_model, train_loader)) # compute training accuracy \n",
    "    val_acc.append(test_acc)  # compute validation accuracy\n",
    "        \n",
    "\n",
    "print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
    "print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  2.0528, -8.5867, -8.8625, -8.7360],\n",
       "        [ 1.0000,  2.0528, -8.5867, -8.8625, -8.7360]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_1_text = \"I do not like this movie\"\n",
    "example_2_text = \"I like this movie\"\n",
    "examples = vectorizer.transform([review_to_words(example_1_text), review_to_words(example_2_text)])\n",
    "examples = torch.from_numpy(examples.toarray()).to(device).float()\n",
    "bow_model(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_1_text = \"The topic of this movie is love\"\n",
    "example_2_text = \"I love a movie about this topic\"\n",
    "examples = vectorizer.transform([review_to_words(example_1_text), review_to_words(example_2_text)])\n",
    "examples = torch.from_numpy(examples.toarray()).to(device).float()\n",
    "bow_model(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddingi w języku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 31.6/31.6MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "corpus = api.load('text8')\n",
    "gensim_model = Word2Vec(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.5657874 ,  0.5802301 ,  0.9599842 ,  2.0401988 ,  0.01017607,\n",
       "        1.1154113 , -0.85396296,  2.0660126 ,  2.6399565 ,  2.9544566 ,\n",
       "       -1.8765633 , -0.8399683 ,  1.4141318 ,  4.705701  , -0.8436778 ,\n",
       "       -0.3072934 ,  0.81900316,  0.4503999 ,  1.2212082 , -1.1091694 ,\n",
       "        0.7618282 ,  3.2822568 ,  0.4011031 , -1.8764749 , -0.77005416,\n",
       "        2.177788  ,  1.3152901 ,  0.06356505,  1.297119  , -1.6865342 ,\n",
       "       -2.23248   , -2.2781546 , -1.2313408 ,  2.5466423 ,  3.1863596 ,\n",
       "        0.17073743,  1.6195778 , -1.5730758 , -1.1301043 , -0.8800659 ,\n",
       "       -0.01639194,  2.158868  ,  2.2817113 , -0.14898838, -2.533003  ,\n",
       "       -3.7532387 ,  0.65051943, -0.56905884,  0.30774218, -2.0587833 ,\n",
       "        2.9412203 ,  0.03276407,  0.34447792,  3.1777818 , -0.66052824,\n",
       "       -1.0458318 ,  0.27254787, -0.60216904,  0.6171592 , -0.95643073,\n",
       "       -0.16799724,  0.36829904,  2.2839334 ,  0.23976076,  0.29311976,\n",
       "        0.48641133, -1.9033241 ,  1.6407989 ,  1.5431995 , -1.6763976 ,\n",
       "        1.828047  ,  1.186891  , -2.8515952 , -2.2766612 ,  2.0019016 ,\n",
       "       -1.089194  ,  0.90019   ,  1.4414934 , -4.210253  ,  3.6411352 ,\n",
       "       -2.111735  , -3.207991  ,  0.34690294,  0.8006895 , -0.00510501,\n",
       "        1.6810726 ,  1.2883576 ,  0.21820624, -0.16224508, -0.9400843 ,\n",
       "       -0.3913621 , -0.39723453,  0.7352897 , -0.24541023,  0.7624985 ,\n",
       "        0.6036596 ,  0.4924871 , -0.33967474, -2.0920386 ,  0.1430908 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model.wv[\"king\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prince', 0.7409482598304749),\n",
       " ('queen', 0.7156945466995239),\n",
       " ('throne', 0.7051340341567993),\n",
       " ('emperor', 0.7011431455612183),\n",
       " ('kings', 0.6847633123397827),\n",
       " ('pharaoh', 0.6745529174804688),\n",
       " ('elector', 0.6614885330200195),\n",
       " ('vii', 0.6604482531547546),\n",
       " ('regent', 0.6591832637786865),\n",
       " ('pope', 0.6554479002952576)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model.wv.most_similar(\"king\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('driver', 0.7869330644607544),\n",
       " ('motorcycle', 0.7475911974906921),\n",
       " ('cars', 0.7252281904220581),\n",
       " ('truck', 0.7071693539619446),\n",
       " ('taxi', 0.6833131313323975),\n",
       " ('vehicle', 0.681018054485321),\n",
       " ('racing', 0.6756450533866882),\n",
       " ('factory', 0.6654843091964722),\n",
       " ('passenger', 0.6454323530197144),\n",
       " ('volkswagen', 0.6451643109321594)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model.wv.most_similar(\"car\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loving', 0.6893803477287292),\n",
       " ('passion', 0.6445050835609436),\n",
       " ('me', 0.644493043422699),\n",
       " ('thee', 0.631065845489502),\n",
       " ('grace', 0.6283605098724365),\n",
       " ('praise', 0.624407947063446),\n",
       " ('delight', 0.6222241520881653),\n",
       " ('soul', 0.6203266382217407),\n",
       " ('enthusiasm', 0.6119697690010071),\n",
       " ('affection', 0.6082258224487305)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model.wv.most_similar(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jak trenować embeddingi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6151,  0.2512,  0.7137,  0.4065,  2.0725]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "word_to_ix = {\"hello\": 0, \"world\": 1}\n",
    "embeds = nn.Embedding(2, 5)  # 2 words in vocab, 5 dimensional embeddings\n",
    "lookup_tensor = torch.tensor([word_to_ix[\"hello\"]], dtype=torch.long)\n",
    "hello_embed = embeds(lookup_tensor)\n",
    "print(hello_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Czyli wklejamy warstwę nn.Embedding uczymy tak jak powyżej i już?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Bag-of-Words - przewidywanie słowa na podstawie kontekstu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuous Bag-of-Words - przewidywanie słowa w środku na podstawie słów zewnętrznych (otaczających dane słowo).\n",
    "\n",
    "### Skip-gram - przewidywanie słów zewnętrznych (otaczających dane słowo), na podstawie słowa w środku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'are', 'about', 'to', 'study', 'the', 'idea', 'of', 'a', 'computational', 'process.', 'computational', 'processes', 'are', 'abstract', 'beings', 'that', 'inhabit', 'computers.', 'as']\n",
      "[(['are', 'we', 'to', 'study'], 'about'), (['about', 'are', 'study', 'the'], 'to'), (['to', 'about', 'the', 'idea'], 'study')]\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 10\n",
    "test_sentence = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".lower().split()\n",
    "\n",
    "ngrams = [\n",
    "    (\n",
    "        [test_sentence[i - j - 1] for j in range(CONTEXT_SIZE)] + [test_sentence[i+  j + 1] for j in range(CONTEXT_SIZE)],\n",
    "        test_sentence[i]\n",
    "    )\n",
    "    for i in range(CONTEXT_SIZE, len(test_sentence)-CONTEXT_SIZE)\n",
    "]\n",
    "# Print the first 3, just so you can see what they look like.\n",
    "print(test_sentence[:20])\n",
    "print(ngrams[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(test_sentence)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(2 * context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227.2811005115509\n",
      "181.76360392570496\n",
      "141.55409693717957\n",
      "100.90656274557114\n",
      "64.90406593680382\n",
      "38.37057527899742\n",
      "22.416560471057892\n",
      "13.877818562090397\n",
      "9.395402189344168\n",
      "6.824199263006449\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "emb_model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.Adam(emb_model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(10):\n",
    "    total_loss = 0\n",
    "    for context, target in ngrams:\n",
    "\n",
    "        # Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in tensors)\n",
    "        context_idxs = torch.tensor([word_to_ix[w] for w in context], dtype=torch.long)\n",
    "        emb_model.zero_grad()\n",
    "        log_probs = emb_model(context_idxs)\n",
    "        loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(total_loss)\n",
    "    losses.append(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3639,  1.4258, -1.7086,  0.2007, -1.4494,  0.4618, -0.1563,  0.0508,\n",
      "        -0.8541,  0.1580], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(emb_model.embeddings.weight[word_to_ix[\"computer\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3210,  0.1566, -1.0241,  0.5554,  1.9930, -2.0359,  0.6621, -2.6735,\n",
      "        -0.7381, -0.8546], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(emb_model.embeddings.weight[word_to_ix[\"computational\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0841])\n",
      "tensor([-0.2073])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    sim1 = torch.cosine_similarity(emb_model.embeddings.weight[word_to_ix[\"process\"]].unsqueeze(0),emb_model.embeddings.weight[word_to_ix[\"computational\"]].unsqueeze(0))\n",
    "    sim2 = torch.cosine_similarity(emb_model.embeddings.weight[word_to_ix[\"process\"]].unsqueeze(0),emb_model.embeddings.weight[word_to_ix[\"study\"]].unsqueeze(0))\n",
    "\n",
    "print(sim1)\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([46, 10])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.embeddings.weight.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini zadanie - zaimplementuj skip-gram - w odwrotną stronę\n",
    "Przewidujmy kontekst w oparciu o jedno słowo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def softmax(x):\n",
    "\t\"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "\te_x = np.exp(x - np.max(x))\n",
    "\treturn e_x / e_x.sum()\n",
    "\n",
    "class word2vec(object):\n",
    "\tdef __init__(self):\n",
    "\t\tself.N = 10\n",
    "\t\tself.X_train = []\n",
    "\t\tself.y_train = []\n",
    "\t\tself.window_size = 2\n",
    "\t\tself.alpha = 0.001\n",
    "\t\tself.words = []\n",
    "\t\tself.word_index = {}\n",
    "\n",
    "\tdef initialize(self,V,data):\n",
    "\t\tself.V = V\n",
    "\t\tself.W = np.random.uniform(-0.8, 0.8, (self.V, self.N))\n",
    "\t\tself.W1 = np.random.uniform(-0.8, 0.8, (self.N, self.V))\n",
    "\t\t\n",
    "\t\tself.words = data\n",
    "\t\tfor i in range(len(data)):\n",
    "\t\t\tself.word_index[data[i]] = i\n",
    "\n",
    "\t\n",
    "\tdef feed_forward(self,X):\n",
    "\t\tself.h = np.dot(self.W.T,X).reshape(self.N,1)\n",
    "\t\tself.u = np.dot(self.W1.T,self.h)\n",
    "\t\t#print(self.u)\n",
    "\t\tself.y = softmax(self.u)\n",
    "\t\treturn self.y\n",
    "\t\t\n",
    "\tdef backpropagate(self,x,t):\n",
    "\t\te = self.y - np.asarray(t).reshape(self.V,1)\n",
    "\t\t# e.shape is V x 1\n",
    "\t\tdLdW1 = np.dot(self.h,e.T)\n",
    "\t\tX = np.array(x).reshape(self.V,1)\n",
    "\t\tdLdW = np.dot(X, np.dot(self.W1,e).T)\n",
    "\t\tself.W1 = self.W1 - self.alpha*dLdW1\n",
    "\t\tself.W = self.W - self.alpha*dLdW\n",
    "\t\t\n",
    "\tdef train(self,epochs):\n",
    "\t\tfor x in range(1,epochs):\t\n",
    "\t\t\tself.loss = 0\n",
    "\t\t\tfor j in range(len(self.X_train)):\n",
    "\t\t\t\tself.feed_forward(self.X_train[j])\n",
    "\t\t\t\tself.backpropagate(self.X_train[j],self.y_train[j])\n",
    "\t\t\t\tC = 0\n",
    "\t\t\t\tfor m in range(self.V):\n",
    "\t\t\t\t\tif(self.y_train[j][m]):\n",
    "\t\t\t\t\t\tself.loss += -1*self.u[m][0]\n",
    "\t\t\t\t\t\tC += 1\n",
    "\t\t\t\tself.loss += C*np.log(np.sum(np.exp(self.u)))\n",
    "\t\t\tprint(\"epoch \",x, \" loss = \",self.loss)\n",
    "\t\t\tself.alpha *= 1/( (1+self.alpha*x) )\n",
    "\t\t\t\n",
    "\tdef predict(self,word,number_of_predictions):\n",
    "\t\tif word in self.words:\n",
    "\t\t\tindex = self.word_index[word]\n",
    "\t\t\tX = [0 for i in range(self.V)]\n",
    "\t\t\tX[index] = 1\n",
    "\t\t\tprediction = self.feed_forward(X)\n",
    "\t\t\toutput = {}\n",
    "\t\t\tfor i in range(self.V):\n",
    "\t\t\t\toutput[prediction[i][0]] = i\n",
    "\t\t\t\n",
    "\t\t\ttop_context_words = []\n",
    "\t\t\tfor k in sorted(output,reverse=True):\n",
    "\t\t\t\ttop_context_words.append(self.words[output[k]])\n",
    "\t\t\t\tif(len(top_context_words)>=number_of_predictions):\n",
    "\t\t\t\t\tbreak\n",
    "\t\n",
    "\t\t\treturn top_context_words\n",
    "\t\telse:\n",
    "\t\t\tprint(\"Word not found in dictionary\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(corpus):\n",
    "\tstop_words = set(stopwords.words('english'))\n",
    "\ttraining_data = []\n",
    "\tsentences = corpus.split(\".\")\n",
    "\tfor i in range(len(sentences)):\n",
    "\t\tsentences[i] = sentences[i].strip()\n",
    "\t\tsentence = sentences[i].split()\n",
    "\t\tx = [word.strip(string.punctuation) for word in sentence\n",
    "\t\t\t\t\t\t\t\t\tif word not in stop_words]\n",
    "\t\tx = [word.lower() for word in x]\n",
    "\t\ttraining_data.append(x)\n",
    "\treturn training_data\n",
    "\t\n",
    "\n",
    "def prepare_data_for_training(sentences,w2v):\n",
    "\tdata = {}\n",
    "\tfor sentence in sentences:\n",
    "\t\tfor word in sentence:\n",
    "\t\t\tif word not in data:\n",
    "\t\t\t\tdata[word] = 1\n",
    "\t\t\telse:\n",
    "\t\t\t\tdata[word] += 1\n",
    "\tV = len(data)\n",
    "\tdata = sorted(list(data.keys()))\n",
    "\tvocab = {}\n",
    "\tfor i in range(len(data)):\n",
    "\t\tvocab[data[i]] = i\n",
    "\t\n",
    "\t#for i in range(len(words)):\n",
    "\tfor sentence in sentences:\n",
    "\t\tfor i in range(len(sentence)):\n",
    "\t\t\tcenter_word = [0 for x in range(V)]\n",
    "\t\t\tcenter_word[vocab[sentence[i]]] = 1\n",
    "\t\t\tcontext = [0 for x in range(V)]\n",
    "\t\t\t\n",
    "\t\t\tfor j in range(i-w2v.window_size,i+w2v.window_size):\n",
    "\t\t\t\tif i!=j and j>=0 and j<len(sentence):\n",
    "\t\t\t\t\tcontext[vocab[sentence[j]]] += 1\n",
    "\t\t\tw2v.X_train.append(center_word)\n",
    "\t\t\tw2v.y_train.append(context)\n",
    "\tw2v.initialize(V,data)\n",
    "\n",
    "\treturn w2v.X_train, w2v.y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rozwiązywanie problemów z wykorzystaniem embeddingów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_weights = torch.FloatTensor(gensim_model.wv.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([71290, 100])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_weights.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding.from_pretrained(emb_weights)\n",
    "embedding.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = gensim_model.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_reviews_tokenized = []\n",
    "for review in reviews['sentence']:\n",
    "    unknows = 0\n",
    "    all_parsed = 0\n",
    "    review_tokenized = []\n",
    "    for word in review.split():\n",
    "        all_parsed+=1\n",
    "        try:\n",
    "            review_tokenized.append(tokenizer[word.lower()])\n",
    "        except:\n",
    "            unknows +=1\n",
    "#     print(unknows/all_parsed)\n",
    "    clean_train_reviews_tokenized.append(review_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, data,labels):\n",
    "        self.data = []\n",
    "        for d, l in zip(data,labels):\n",
    "            self.data.append((torch.from_numpy(np.array(d)).long(),torch.tensor(l).long()))\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        in_data, target = self.data[idx]\n",
    "        return in_data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ReviewDataset(np.array(clean_train_reviews_tokenized, dtype=object)[train_indices],reviews[\"label\"].values[train_indices])\n",
    "test_data = ReviewDataset(np.array(clean_train_reviews_tokenized, dtype=object)[~train_indices],reviews[\"label\"].values[~train_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def pad_collate(batch):\n",
    "    (xx, yy) = zip(*batch)\n",
    "    x_lens = [len(x)-1 for x in xx]\n",
    "\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=0)\n",
    "    yy = torch.stack(yy)\n",
    "    return xx_pad, yy, x_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=32, collate_fn=pad_collate, shuffle=True,drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, collate_fn=pad_collate, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMRegressor(\n",
       "  (embeddings): Embedding(71290, 100)\n",
       "  (lstm): LSTM(100, 100)\n",
       "  (fc): Linear(in_features=100, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, out_size, emb_weights, bidirectional = False):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        if bidirectional:\n",
    "            self.bidirectional = 2\n",
    "        else:\n",
    "            self.bidirectional = 1\n",
    "        self.embeddings = nn.Embedding.from_pretrained(emb_weights)\n",
    "        self.embeddings.requires_grad = False\n",
    "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, bidirectional=bidirectional, batch_first=False)\n",
    "        self.fc = nn.Linear(hidden_size*self.bidirectional, out_size)\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
    "        state = torch.zeros(self.num_layers*self.bidirectional , batch_size, self.hidden_size)\n",
    "        return hidden, state\n",
    "    \n",
    "    def forward(self, x, len_x, hidden):\n",
    "        x = self.embeddings(x)\n",
    "        x = torch.transpose(x,0,1)\n",
    "        all_outputs, hidden = self.lstm(x, hidden)\n",
    "        all_outputs = torch.transpose(all_outputs,0,1)\n",
    "        last_seq_items = all_outputs[range(all_outputs.shape[0]), len_x]  # mozna podobno wykorzystac amiast tego pad_sequence\n",
    "        out = last_seq_items#all_outputs[-1]#torch.flatten(all_outputs,1)\n",
    "        x = self.fc(out)\n",
    "        return x, hidden\n",
    "     \n",
    "lstm_model = LSTMRegressor(100, 100, 1, 5, emb_weights).to(device)\n",
    "lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr = 0.001)\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "lstm_model.train()\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(101):\n",
    "    losses = 0\n",
    "    batches = 0\n",
    "    for x, targets, len_x in train_loader:\n",
    "        x = x.to(device)\n",
    "        targets = targets.to(device)\n",
    "        hidden, state = lstm_model.init_hidden(x.size(0))\n",
    "        hidden, state = hidden.to(device), state.to(device) \n",
    "        preds, _ = lstm_model(x, len_x, (hidden,state))\n",
    "        preds = preds.squeeze(1)\n",
    "        optimizer.zero_grad() \n",
    "        loss = loss_fun(preds, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "        batches +=1\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, loss: {losses/batches:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.load_state_dict(torch.load(\"lab_13/lstm_model_dict\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.eval()\n",
    "with torch.no_grad():\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    for x, targets, len_x in test_loader:\n",
    "        x = x.to(device)\n",
    "        targets_list.append(targets.numpy())\n",
    "        targets = targets.to(device)\n",
    "        hidden, state = lstm_model.init_hidden(x.size(0))\n",
    "        hidden, state = hidden.to(device), state.to(device) \n",
    "        preds, _ = lstm_model(x, len_x, (hidden,state))\n",
    "        preds = preds.squeeze(1)\n",
    "        preds_list.append(preds.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Test accuracy: {(np.argmax((np.concatenate(preds_list)),1) == np.concatenate(targets_list)).sum()/len(np.concatenate(targets_list)):.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_1_text = \"I do not like this movie\"\n",
    "example_2_text = \"I like this movie\"\n",
    "example_1_tokenized = []\n",
    "for word in example_1_text.split():\n",
    "    try:\n",
    "        example_1_tokenized.append(tokenizer[word])\n",
    "    except:\n",
    "        continue\n",
    "example_2_tokenized = []\n",
    "for word in example_2_text.split():\n",
    "    try:\n",
    "        example_2_tokenized.append(tokenizer[word])\n",
    "    except:\n",
    "        continue\n",
    "hidden, state = lstm_model.init_hidden(1)\n",
    "hidden, state = hidden.to(device), state.to(device) \n",
    "preds_1,_ = lstm_model(torch.from_numpy(np.array(example_1_tokenized)).unsqueeze(0).to(device),len(example_1_tokenized)-1,(hidden,state))\n",
    "preds_2,_ = lstm_model(torch.from_numpy(np.array(example_2_tokenized)).unsqueeze(0).to(device),len(example_2_tokenized)-1,(hidden,state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(preds_1)\n",
    "print(preds_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arytmetyka na embeddingach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2875329 , -0.08550619,  0.602173  ,  1.5514168 ,  0.3672185 ,\n",
       "       -0.10551011, -0.17370196, -1.570191  , -0.60101414, -0.8173157 ,\n",
       "        0.5996032 , -0.7143638 , -0.68850845,  1.9368598 , -1.6900142 ,\n",
       "       -2.7346354 ,  1.3289776 , -0.57430017,  0.54205525, -0.73181176,\n",
       "        0.5991014 ,  1.0659971 ,  0.1673821 ,  1.7105665 , -0.00965753,\n",
       "       -0.08989599, -1.5234284 ,  1.0417117 , -0.01916429,  1.5629625 ,\n",
       "        1.5292557 ,  1.3768628 ,  1.1352034 ,  0.2869554 , -2.0971897 ,\n",
       "       -0.86090016, -0.63100165, -1.6325328 , -0.95291054, -1.4224738 ,\n",
       "        2.179335  , -2.8646321 , -1.0523094 ,  0.5544337 ,  0.6308973 ,\n",
       "       -1.0084468 , -2.0665243 , -1.1400266 ,  3.059631  , -1.3022546 ,\n",
       "       -0.12872046, -0.91426045,  1.094659  , -0.46210143,  0.875928  ,\n",
       "        2.2807074 ,  1.1741854 , -1.0181057 ,  0.3571827 ,  0.7049601 ,\n",
       "        0.82867646,  0.34350118,  0.19895534, -0.40053272, -0.983118  ,\n",
       "       -1.331916  , -2.516357  ,  0.62189007,  0.070021  , -2.8141706 ,\n",
       "        2.072242  , -2.4915729 ,  0.43970028,  0.7528817 , -1.0371207 ,\n",
       "        1.9360007 , -1.8215933 ,  1.5900476 ,  0.07278366,  0.46736223,\n",
       "       -1.2537212 , -0.94316965,  0.4013574 ,  2.8030615 , -2.0397477 ,\n",
       "        0.5957348 ,  1.1156034 , -2.2133164 , -0.16586016, -0.03557253,\n",
       "        0.25168636, -1.634445  , -2.3542461 , -0.27438363,  0.5059011 ,\n",
       "       -2.0086026 ,  0.13564284,  0.4469677 ,  1.0579802 ,  2.0014586 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model.wv[\"car\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "982"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer[\"car\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2875, -0.0855,  0.6022,  1.5514,  0.3672, -0.1055, -0.1737, -1.5702,\n",
       "        -0.6010, -0.8173,  0.5996, -0.7144, -0.6885,  1.9369, -1.6900, -2.7346,\n",
       "         1.3290, -0.5743,  0.5421, -0.7318,  0.5991,  1.0660,  0.1674,  1.7106,\n",
       "        -0.0097, -0.0899, -1.5234,  1.0417, -0.0192,  1.5630,  1.5293,  1.3769,\n",
       "         1.1352,  0.2870, -2.0972, -0.8609, -0.6310, -1.6325, -0.9529, -1.4225,\n",
       "         2.1793, -2.8646, -1.0523,  0.5544,  0.6309, -1.0084, -2.0665, -1.1400,\n",
       "         3.0596, -1.3023, -0.1287, -0.9143,  1.0947, -0.4621,  0.8759,  2.2807,\n",
       "         1.1742, -1.0181,  0.3572,  0.7050,  0.8287,  0.3435,  0.1990, -0.4005,\n",
       "        -0.9831, -1.3319, -2.5164,  0.6219,  0.0700, -2.8142,  2.0722, -2.4916,\n",
       "         0.4397,  0.7529, -1.0371,  1.9360, -1.8216,  1.5900,  0.0728,  0.4674,\n",
       "        -1.2537, -0.9432,  0.4014,  2.8031, -2.0397,  0.5957,  1.1156, -2.2133,\n",
       "        -0.1659, -0.0356,  0.2517, -1.6344, -2.3542, -0.2744,  0.5059, -2.0086,\n",
       "         0.1356,  0.4470,  1.0580,  2.0015])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_weights[tokenizer[\"car\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,4))\n",
    "sns.heatmap([gensim_model.wv[\"king\"], \n",
    "             gensim_model.wv[\"man\"], \n",
    "             gensim_model.wv[\"woman\"], \n",
    "             gensim_model.wv[\"king\"] - gensim_model.wv[\"man\"] + gensim_model.wv[\"woman\"],\n",
    "             gensim_model.wv[\"queen\"],\n",
    "            ], cbar=True, xticklabels=False, yticklabels=False,linewidths=1,cmap=\"vlag\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = gensim_model.wv[\"paris\"] + gensim_model.wv[\"germany\"] - gensim_model.wv[\"berlin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.8919679 , -0.20547116,  0.6892623 ,  1.2385235 ,  1.2700441 ,\n",
       "       -1.3714788 , -2.264701  ,  2.3785021 ,  0.51728535,  1.0286282 ,\n",
       "       -0.5796881 , -0.10380822, -0.7337619 , -0.9656749 , -0.7689143 ,\n",
       "       -0.58741957, -1.458168  , -0.58896554,  0.8173344 , -3.9580445 ,\n",
       "        5.1510587 ,  1.9139725 ,  0.5688826 ,  0.5130929 , -1.1744236 ,\n",
       "        2.14064   , -0.34519386,  1.814579  ,  1.7292175 , -1.2431492 ,\n",
       "       -3.2576442 , -0.42534783,  0.7432444 ,  1.9001745 , -0.6613988 ,\n",
       "        2.351651  , -0.16808593, -2.1748931 , -0.31410235, -2.5854259 ,\n",
       "       -0.8282623 ,  1.2231399 , -2.99468   , -1.3503776 ,  0.29197553,\n",
       "        0.45788762,  1.127783  ,  0.23798816, -1.0942612 , -1.9327087 ,\n",
       "        2.8371294 ,  0.6900089 ,  1.0411884 ,  1.0332592 ,  1.7357116 ,\n",
       "        1.7034659 ,  1.8499067 ,  1.7247462 , -1.26912   ,  1.417038  ,\n",
       "        3.3587997 ,  1.8756887 ,  1.23452   , -0.46674055, -1.183068  ,\n",
       "       -1.1504893 ,  0.56879294,  1.3338518 ,  0.5837897 , -1.5088091 ,\n",
       "        0.26008642, -1.0364971 , -3.3041816 ,  0.6711019 , -1.5520346 ,\n",
       "       -2.7376125 , -0.02228224,  0.85426736,  1.1085136 , -0.8103402 ,\n",
       "       -2.1754582 , -0.6345054 ,  2.1635995 ,  1.8398744 ,  0.40080285,\n",
       "        1.0690444 ,  5.152909  , -1.89887   , -0.79170275,  1.1042042 ,\n",
       "        0.693766  , -1.0576336 , -0.55243945, -3.787586  ,  2.8659413 ,\n",
       "        1.7070818 ,  2.2546823 , -0.23356187,  0.8857217 ,  0.27410197],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('germany', 0.772567093372345),\n",
       " ('france', 0.7692506909370422),\n",
       " ('italy', 0.763939380645752),\n",
       " ('paris', 0.759231448173523),\n",
       " ('spain', 0.6708950400352478),\n",
       " ('switzerland', 0.6493278741836548),\n",
       " ('belgium', 0.6480931043624878),\n",
       " ('austria', 0.6355417966842651),\n",
       " ('portugal', 0.5987979769706726),\n",
       " ('venice', 0.5922741293907166)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model.wv.most_similar(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.8481572 ,  1.4358995 ,  1.1210982 ,  0.49079347,  1.5217392 ,\n",
       "        1.1375062 , -0.5457898 ,  3.6933763 ,  0.89648855,  0.8966094 ,\n",
       "        0.10324363,  1.9829222 , -1.6448555 ,  0.20337754,  0.0551339 ,\n",
       "        0.8032338 , -0.31656268,  0.8430107 , -0.7841185 , -4.326267  ,\n",
       "        3.5980556 ,  1.937438  , -0.5598738 ,  0.24477632, -2.3196602 ,\n",
       "        1.2665285 ,  0.3519903 ,  1.2993324 ,  1.5666205 , -2.6493065 ,\n",
       "       -1.7349687 , -0.16536497,  0.9653249 ,  0.3972919 ,  1.0909655 ,\n",
       "        1.3831468 ,  0.6179445 , -1.2737826 , -1.233569  , -1.0550328 ,\n",
       "       -0.53933865,  1.0337771 , -0.9163713 , -0.99345237, -0.30156055,\n",
       "        2.1620693 ,  0.98299366,  0.22673291, -1.0645688 , -0.788596  ,\n",
       "        2.9771056 ,  0.904583  ,  0.8720574 ,  0.7503692 ,  0.5381557 ,\n",
       "        1.7094492 ,  2.021951  ,  0.3020667 ,  0.051583  , -0.05115681,\n",
       "        0.10006049,  1.0581207 ,  1.2859426 , -1.0524634 , -0.44664475,\n",
       "       -1.0036279 ,  0.89804405,  1.1607999 ,  0.5447022 , -2.3125308 ,\n",
       "       -1.6467791 ,  0.8263791 , -1.639864  , -0.26305565, -0.7563424 ,\n",
       "       -1.7518734 , -1.0548341 ,  0.3523178 , -0.38224834,  0.14629668,\n",
       "       -0.80067074, -0.22137508,  1.3824785 ,  2.197514  ,  0.9701084 ,\n",
       "        0.66626394,  3.5412805 , -1.0124696 , -0.9931142 , -0.60494614,\n",
       "        0.76551497, -1.998064  , -1.0751585 , -2.1922634 ,  1.9652513 ,\n",
       "        0.48347414,  1.2677298 ,  0.09492437,  0.7505017 , -0.8699399 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim_model.wv[\"france\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.8919679 , -0.20547116,  0.6892623 ,  1.2385235 ,  1.2700441 ,\n",
       "        -1.3714788 , -2.264701  ,  2.3785021 ,  0.51728535,  1.0286282 ,\n",
       "        -0.5796881 , -0.10380822, -0.7337619 , -0.9656749 , -0.7689143 ,\n",
       "        -0.58741957, -1.458168  , -0.58896554,  0.8173344 , -3.9580445 ,\n",
       "         5.1510587 ,  1.9139725 ,  0.5688826 ,  0.5130929 , -1.1744236 ,\n",
       "         2.14064   , -0.34519386,  1.814579  ,  1.7292175 , -1.2431492 ,\n",
       "        -3.2576442 , -0.42534783,  0.7432444 ,  1.9001745 , -0.6613988 ,\n",
       "         2.351651  , -0.16808593, -2.1748931 , -0.31410235, -2.5854259 ,\n",
       "        -0.8282623 ,  1.2231399 , -2.99468   , -1.3503776 ,  0.29197553,\n",
       "         0.45788762,  1.127783  ,  0.23798816, -1.0942612 , -1.9327087 ,\n",
       "         2.8371294 ,  0.6900089 ,  1.0411884 ,  1.0332592 ,  1.7357116 ,\n",
       "         1.7034659 ,  1.8499067 ,  1.7247462 , -1.26912   ,  1.417038  ,\n",
       "         3.3587997 ,  1.8756887 ,  1.23452   , -0.46674055, -1.183068  ,\n",
       "        -1.1504893 ,  0.56879294,  1.3338518 ,  0.5837897 , -1.5088091 ,\n",
       "         0.26008642, -1.0364971 , -3.3041816 ,  0.6711019 , -1.5520346 ,\n",
       "        -2.7376125 , -0.02228224,  0.85426736,  1.1085136 , -0.8103402 ,\n",
       "        -2.1754582 , -0.6345054 ,  2.1635995 ,  1.8398744 ,  0.40080285,\n",
       "         1.0690444 ,  5.152909  , -1.89887   , -0.79170275,  1.1042042 ,\n",
       "         0.693766  , -1.0576336 , -0.55243945, -3.787586  ,  2.8659413 ,\n",
       "         1.7070818 ,  2.2546823 , -0.23356187,  0.8857217 ,  0.27410197]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_most_similar_word(vec, word_vec):\n",
    "    vec_reshaped = [vec]\n",
    "        \n",
    "    distances = [cosine_similarity(vec_reshaped, [word_vec[i]]) for i in range(len(word_vec))]\n",
    "    max_distance_idx = distances.index(max(distances))\n",
    "    return max_distance_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = get_most_similar_word(x, gensim_model.wv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSNE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd6aaa34b2eaa27615c35a49f49fcac2b9fb6ef67dd9795ab23618a0054bdc5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
